{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressão \n",
    "\n",
    "#### Foi usado uma base de dados de características de casas com o valor delas, para se fazer uma regressão, é um método puramente estatístico. Foi usado as bibliotecas scikit learn( biblioteca de algoritmos de ML e métricas) e pandas (biblioteca de funçĩes para manipulação de base de dados).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score , mean_absolute_error\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "rg1 = pd.read_csv('train.csv')\n",
    "\n",
    "rgY = rg1['SalePrice']\n",
    "\n",
    "rg1 = rg1.drop(columns=['Id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Foi utilizado uma função para medir a correlação do Frame, e usado a coluna das correlações com o objetivo que é 'SalePrice', assim foi possível retirar as características com menor correlação com o alvo, deixando a regressão mais precisa e com o menor erro possível."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MSSubClass', 'OverallCond', 'BsmtFinSF2', 'BsmtUnfSF', 'LowQualFinSF',\n",
       "       'BsmtFullBath', 'BsmtHalfBath', 'BedroomAbvGr', 'KitchenAbvGr',\n",
       "       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal',\n",
       "       'MoSold', 'YrSold'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cor = rg1.corr()\n",
    "\n",
    "cor_target = cor[\"SalePrice\"]\n",
    "\n",
    "irrelevant_features = cor_target[cor_target < 0.25]\n",
    "irrelevant_features.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Após retirar as características com menor correlação, foi preenchido a característica 'GarageYrBlt', com valores já existentes nessa coluna, pois seria ruim usar a média ou mediana como valor para os dados faltosos, visando que em um cálculo isso pode criar um vies negativo no resultado. Então foi tratado os valores vazios com uma string indicando NaN, isso foi feito pois nessa base, os valores nulos em algumas colunas representam que aquela característica não está presente no imóvel, depois disso foi usado o LabelEncoder para transformar os objetos em valores numéricos, pois seria impossível usar os modelos em strings, e foi normalizado para tentar melhorar os resultados, mas isso foi pouco efetivo nesse caso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg = rg1.drop(columns= irrelevant_features.index)\n",
    "\n",
    "rgX = rg.drop(columns='SalePrice')\n",
    "\n",
    "rgX['GarageYrBlt'] = rgX['GarageYrBlt'].interpolate(method= 'pad')\n",
    "\n",
    "rgX = rgX.fillna('NaN')\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "for i in rgX.columns:\n",
    "\tif rgX[i].dtypes == 'object':\n",
    "\t\trgX[i] = le.fit_transform(rgX[i].astype(str))\n",
    "\t\n",
    "# rgX = Normalizer().fit_transform(rgX)\n",
    "\n",
    "\n",
    "trainX, testX, trainY, testY = train_test_split(rgX,rgY, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayes Score: 0.8626036585216369 19994.537071663464\n"
     ]
    }
   ],
   "source": [
    "Bayes = linear_model.BayesianRidge()\n",
    "\n",
    "Bayes.fit(trainX, trainY)\n",
    "\n",
    "BayesPredict = Bayes.predict(testX)\n",
    "\n",
    "print(\"Bayes Score:\" , r2_score(testY, BayesPredict), mean_absolute_error(testY, BayesPredict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Score: 0.845642506876757 21100.982262789392\n"
     ]
    }
   ],
   "source": [
    "Linear = linear_model.LinearRegression()\n",
    "\n",
    "Linear.fit(trainX, trainY)\n",
    "\n",
    "LinearPredict = Linear.predict(testX)\n",
    "\n",
    "print(\"Linear Score:\", r2_score(testY, LinearPredict), mean_absolute_error(testY, LinearPredict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighbors Score: 0.6885148696780714 29169.724260892785\n"
     ]
    }
   ],
   "source": [
    "Neighbors = KNeighborsRegressor(n_neighbors = 9, weights = 'distance')\n",
    "\n",
    "Neighbors.fit(trainX, trainY)\n",
    "\n",
    "NeighborsPredict = Neighbors.predict(testX)\n",
    "\n",
    "print(\"KNeighbors Score:\", r2_score(testY, NeighborsPredict) , mean_absolute_error(testY, NeighborsPredict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree Score: 0.7309479357381337 26566.87436571258\n"
     ]
    }
   ],
   "source": [
    "Tree = DecisionTreeRegressor(max_depth = 7)\n",
    "\n",
    "Tree.fit(trainX, trainY)\n",
    "\n",
    "TreePredict = Tree.predict(testX)\n",
    "\n",
    "print('Tree Score:', r2_score(testY, TreePredict), mean_absolute_error(testY, TreePredict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rede Neural Score: 0.8150859197574687 22846.019706981184\n"
     ]
    }
   ],
   "source": [
    "Rede = MLPRegressor(learning_rate_init = 0.02,max_iter = 1000, batch_size = 100)\n",
    "\n",
    "Rede.fit(trainX, trainY)\n",
    "\n",
    "RedePredict = Rede.predict(testX)\n",
    "\n",
    "print('Rede Neural Score:', r2_score(testY, RedePredict), mean_absolute_error(testY, RedePredict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados\n",
    "\n",
    "#### Os modelos lineares foram os melhores algoritmos, entre os selecionados, pode-se perceber que eles não só tiveram um menor erro médio como também um coeficiente de determinação maior, isso indica que os modelos se encaixaram melhor nos dados. Isso também se deve pelo fato das características com menor correlação foram tiradas da base, isso influência diretamente nos modelos de regressão linear, deixando-os mais precisos, porém isso não foi observado quando retirado mais valores, a métrica de 25% de correlação foi testada e obteve os melhores resultados, não se pode provar que é a menor média de erros possível, mas nesses testes foram essas duas a melhores: Regressão Linear Bayesiana e Regressão Linear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Média de Erro Absoluto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Regressão Linear Bayesiana</td>\n",
       "      <td>19994.537072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Regressão Linear</td>\n",
       "      <td>21100.982263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Modelo  Média de Erro Absoluto\n",
       "0  Regressão Linear Bayesiana            19994.537072\n",
       "1            Regressão Linear            21100.982263"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame = []\n",
    "\n",
    "frame+= [['Regressão Linear Bayesiana',mean_absolute_error(testY, BayesPredict)]]\n",
    "frame+= [['Regressão Linear',mean_absolute_error(testY, LinearPredict)]]\n",
    "\n",
    "df = pd.DataFrame(frame, columns = ['Modelo','Média de Erro Absoluto'],)\n",
    "\n",
    "df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
